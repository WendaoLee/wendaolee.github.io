---
title: 【WIP】个人梳理的 LLM 阅读材料和文献 - 2025
description: 个人梳理的 LLM 阅读材料和文献，也许它能够帮助到你？
category: wip
date: 2025-01-24 
---

🚧🚧🚧 施工中 🚧🚧🚧

## Prompt Engineering

- 【✨重点推荐，基本把Prompt Engineering 梳理完了】翁荔的博客：Weng, Lilian. (Mar 2023). Prompt Engineering. Lil’Log. https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.
- 

## LLM 测试

- 【Claude】如何开发LLM的测试用例：https://docs.anthropic.com/zh-CN/docs/build-with-claude/develop-tests

  所谓测试，本质是 build evals ，构建评估。

- 【Anthropic 的 Building Evals Cookbook 示例】https://github.com/anthropics/anthropic-cookbook/blob/main/misc/building%5Fevals.ipynb


## Agent

- 【✨重点推荐】翁荔的博客：Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/. 

  > We can roughly consider the following mappings:
  > 我们可以大致考虑以下映射：
  >
  > - Sensory memory as learning embedding representations for raw inputs, including text, image or other modalities;
  >   感官记忆作为学习嵌入表示，适用于包括文本、图像或其他模态的原始输入；
  > - Short-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.
  >   短期记忆即上下文学习。它短暂且有限，受限于 Transformer 的有限上下文窗口长度。
  > - Long-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.
  >   长期记忆作为外部向量存储，代理在查询时可通过快速检索访问。

- 【Anthropic 总结的代理系统的模式】https://leewendao.otterstack.cn/writings/translations/building-effective-agents-zh
- 


  ## 一些通用结论
  
- 【大模型知道自身会在什么时候感到困惑】https://arxiv.org/abs/2410.02707
- 【大模型并不在做推理，仅仅只是复制了在训练数据中观察到的推理步骤，添加一个似乎与问题相关的子句会导致所有最先进的模型的性能显著下降（高达 65%）】https://arxiv.org/abs/2410.05229
- 【test-time scaling，测试时间缩放】给LLM更多的思考时间，它能够得到更好的结果。